{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script follows general pipeline of [the standard CIFAR10 Pytorch example](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html). It extracts grey scale images from the dataset.\n",
    "\n",
    "The steps are:\n",
    "\n",
    "1. Load and normalizing the FRDEEPv 2.0 training and test datasets using torchvision\n",
    "2. Define a Convolutional Neural Network\n",
    "3. Define a loss function (we use AdaGrad here)\n",
    "4. Train the network on the training data (we train on FIRST images here)\n",
    "5. Test the network on the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First import some standard python libraries for plotting stuff and handling arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then import the pytorch, torchvision and torchsummary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then import the pytorch neural network stuff:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then import the oprimization library from pytorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally import the FRDEEP v2.0 pytorch dataset class. This is not provided with pytorch, you need to [grab it from the FRDEEPv2.0 github](\n",
    "[waiting for uploading])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FRDEEPv2_foundation import FRDEEPv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of torchvision datasets are PILImage images of range [0, 1]. We transform them to Tensors of normalized range [-1, 1]. We here also randomly rotate image from -45 to 45 deg (in step of 1 deg) before every epoch of training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.RandomRotation([-45,45]),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize([0.5],[0.5])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in the training and test datasets. The first time you do this it will download the data to your working directory, but once the data is there it will just use it without repeating the download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(460, 150, 150, 1)\n",
      "(460, 150, 150, 1)\n"
     ]
    }
   ],
   "source": [
    "trainset = FRDEEPv2(root1='./4_DataPickle_Generation/',root2='./4_DataPickle_Generation/',root3='./4_DataPickle_Generation/', train=True, download=False, transform=transform)\n",
    "batch_size_train = 2\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size_train, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(198, 150, 150, 1)\n",
      "(198, 150, 150, 1)\n"
     ]
    }
   ],
   "source": [
    "testset = FRDEEPv2(root1='./4_DataPickle_Generation/',root2='./4_DataPickle_Generation/',root3='./4_DataPickle_Generation/', train=False, download=False, transform=transform)\n",
    "batch_size_test = 2\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size_test, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two classes in this dataset: FRI and FRII:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('FRI', 'FRII')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A little function to display images nicely:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    # unnormalize\n",
    "    img = img / 2 + 0.5\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at some randomly selected samples to see how they appear:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images1_tr,images2_tr,object_id_tr,labels_tr = dataiter.next() # images1:NVSS, images2:FIRST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note: images1, images2 -> NVSS image, FIRST image of the same object. For visualizing/training/testing on NVSS image inputs, simply replace images2 with images1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAADLCAYAAABgQVj0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAFltJREFUeJzt3XuMXGd9xvHvs7Mz62yML8s6iR1HtRMsSlJRiIyblAohkkKSAk5FkEyrYtFIVktooS2CpJFqIhUJeoEW0QYZkmKqKBeSQKI2tETBCFVqAkvi3MjNudhZx4kdUjte7+7szu6vf8w5w3izF3vOzM7s2ecjrXbmzNmd3+tz/Ow777m8igjMzCy/utpdgJmZtZaD3sws5xz0ZmY556A3M8s5B72ZWc456M3Mcq5lQS/pEklPSdoj6epWvY+Zmc1OrTiPXlIBeBr4XWAQ+BnwsYj4RdPfzMzMZtWqHv0mYE9EPBcRY8AtwOYWvZeZmc2iu0W/90zgxbrng8BvzbRyb29vrFixokWlmJnl04EDB16NiFVzrdeqoNc0y44bI5K0DdgGsHz5crZt29aiUszM8um6667beyLrtSroB4Gz6p6vBV6qXyEidgA7ANasWRMA1113XYvKMTt527dvrz32vmmdpH7fPBGtGqP/GbBB0npJJWALcHeL3svMzGbRkh59RFQkfQr4b6AA3BgRj7fivczMbHatGrohIu4B7mnV7zez+SMJ39J84fKVsWZmOeegN7NZSdOdRGcLScuGbswsHzxks/C5R29mlnMOejOznHPQm5nlnIPezCznHPRmZjnnoDczyzkHvZlZzjnozcxyzkFvZpZzDnozs5xrOOglnSVpl6QnJD0u6dPJ8j5J90p6Jvm+snnlmpnZycrSo68AfxURbwMuAK6SdC5wNXBfRGwA7kuem5lZmzQc9BFxICIeTB4fBZ6gOin4ZmBnstpO4PKsRZqZWeOaMkYvaR3wTuAB4PSIOADVPwbAac14DzMza0zmoJe0FLgD+ExEvH4SP7dN0oCkgeHh4axlmOWO7wNvzZIp6CUVqYb8TRFxZ7L4FUmrk9dXAwen+9mI2BERGyNiY29vb5YyzHLJ94G3Zsly1o2AG4AnIuIrdS/dDWxNHm8F7mq8PDMzyyrLDFPvBv4IeFTS7mTZXwNfAm6TdCWwD/hothLNrBNJOm7ScH8C6VwNB31E/A8w0yDiRY3+XjNbGNJgrw9760y+MtbMLOc8ObiZNSwi3JtfANyjN7NZpWPxtnC5R29ms3KPfeFzj97MLOcc9GZmOeegNzPLOQe9mVnOOejNzHLOQW9mlnMOejOznHPQm5nlnIPezCznmjHDVEHSQ5L+I3m+XtIDkp6RdKukUvYyzcysUc3o0X+a6sTgqS8DX42IDcD/AVc24T3MzKxBWacSXAv8HvCt5LmA9wG3J6vsBC7P8h5mZpZN1h79PwGfAyaT528GDkdEJXk+CJyZ8T3MFgXfIdJaJcucsR8EDkbEz+sXT7PqtLe+k7RN0oCkgeHh4UbLMMuNiHDYW0tknTP2w5IuA5YAy6j28FdI6k569WuBl6b74YjYAewAWLNmje+DaoZvCWyt0XCPPiKuiYi1EbEO2AL8KCL+ENgFXJGsthW4K3OVZmbWsFacR/954C8l7aE6Zn9DC97DzBYRD2ll05QZpiLix8CPk8fPAZua8XvNzBzy2fnKWDPraJJ87CIjB72ZWc456M3Mcs5Bb2YdbXJycu6VbFYOejOzJunUA8cOejOzJpHUkWHflNMrzczsV0EfEbWvTuAevZlZC3RKyIN79Ga2SHV1dTWt193VVe0zpweOOynkwUFvZotQs8fR02DvtIBPOejNbFGZOo7eDJ0a8CmP0edE2kPp6uqqfYw0szfqpIOk88WJYGaWc1nnjF0h6XZJT0p6QtKFkvok3SvpmeT7ymYVazPr6uqiVCqxbNkylixZQqFQcO/eLJEO16SffBdbrz5rCvwz8F8R8evAbwJPAFcD90XEBuC+5Lm12JIlSzj11FMBWL58OUuWLKGvr4++vj6KxWKbqzNrj/qA79SLmeZDljljlwHvIZlYJCLGIuIwsBnYmay2E7g8a5E2u+7u6jH1np4e+vv7Ofvss1m3bh2FQoFCobBod24zeONtjhfj/4csPfqzgUPAv0l6SNK3JJ0KnB4RBwCS76dN98OeHLx50nN3ly1bRn9/P6VSiWKxSLlcplwuMzk5WftjYJZ3kmrDlulXfbgvpiGbVJag7wbOB66PiHcCxziJYZqI2BERGyNiY29vb4YyrFAo0NPTQ09PD8eOHePIkSMAtaGbQqHAxMREm6s0mx9pkKcBP3XIZjH26LN08waBwYh4IHl+O9Wgf0XS6og4IGk1cDBrkTa7SqXC8PAwhw4dYsWKFRw9epTx8XHST0rj4+OLshdji1ca5vXDNou5V99wjz4iXgZelPTWZNFFwC+Au4GtybKtwF2ZKrQ5pR9VJyYmauE+MjJCpVKhUqm0uTqz+TU10KeG+mI8KJt14PbPgJsklYDngE9Q/eNxm6QrgX3ARzO+h81hcnKS0dFRAMbGxigWi4yOjtZC3hM32GIyU9BPHb6RtGj+b2QK+ojYDWyc5qWLsvxea8zk5CRjY2NMTEwwPj5e24k9Rm+LSUTMeb58/ZXkiyHsfSpGTkQE5XK5NoxTv/Muhh3ZLBURTExM1A7GpsFf37OfuizvfNmkmVnOuUefE/W3SU17K+7J22JW31uf7vFiug2Cgz6HFtMObDaTTr9H/Hxy0JtZS0y9oV47OiAO+SoHvZm1xNRbD0A1eCcnJ5mcnDzu9XS5tYaDPocW09kE1pnq7zOTPk+PG01MTFCpVOjt7aVYLFIsFpmYmGBkZKR2PYiHH5vLQZ8j9ff18Hnz1k5pTz29mV53dzeFQoGIqF2xvWrVKlatWkV/fz8jIyO88MILvPzyy0D1th2+qrt5HPQ5Ian2n6pYLFKpVBgfHwc8Tmnzq77Dke6TpVKJ7u7uWickIli7di2bNm0C4LzzzuO1115j165dADz99NPs27ePcrnctnbkiYM+JyRRLBZrF0sVCoVaj8hBb/MpHW+XVNsHC4UC3d3ddHd3UyqViAgOHz7Miy++yEc+8hEuvvhiBgcH2b9/P1ANeu+3zeOgzwFJFAoFisUi3d3dTExMHDfhyOjoqA902bxI98Wurq7aPgm/OgMnDe/u7m6KxSKnnHIKy5Yto6+vj6NHj9LT0wPA8PCw99kmctDnQPpxuFwu093dTU9PT+3jsdl8qB+qScfj03mMU5OTk1QqFSKiFvyjo6Ps27ePgYEBBgcHGRwcBGBoaMj7bxM56HMgHarp6uqip6fnDb2nUqlEuVz2fxxrmXS/S4dm0k+UadCnN9urVCq1KS7TORQeeugh9u/fz8GDB3nyySeB6h8A76/Nk+leN5L+QtLjkh6TdLOkJZLWS3pA0jOSbk1uYWxmZm3ScI9e0pnAnwPnRsSIpNuALcBlwFcj4hZJ3wCuBK5vSrU2o66urtqY59KlSxkbG6v1pg4dOuTekTVd/bnyy5YtO+5YUaFQAI4/ESDt0ac/k/baR0ZGKBaLHDlypHZ6pc+2aa6sQzfdwCmSxoFe4ADwPuAPktd3Al/AQd9y6Y3MLrzwQnp6eti7dy979+5td1mWQ2mIpwdUS6USK1euPG6drq4uIoJjx44B1ekux8bGqFQqtQv6xsfHKZfLHDlypHab7VSpVGJsbGz+GpVzDQd9ROyX9A9UZ5EaAX4I/Bw4HBHplQ6DwJnT/bykbcA2gOXLlzdahiWWLl3KOeecA8DmzZsBuP/++wG44447ePbZZ30BimVWf258b28vvb29LFmyhL6+PiqVCuVy+bjTeqee4pteGTs+Ps7ExASjo6PHXUGbXujnC/6aK8vQzUpgM7AeOAx8F7h0mlWnHTOIiB3ADoA1a9Z4XCGjkZERjh07xumnn86HPvQhBgcHufPOOwFqvSqzrNKeOFR76aVSieXLl7Nq1SpGRkYYGhpiaGiIkZERxsbGjuvRp1/1p036HjfzI8vQzcXA8xFxCEDSncBvAyskdSe9+rXAS9nLtBNxxhln8K53vYu9e/fy/PPPs3v3bgD6+/s5fPgwQ0NDba7Q8iC9PqOnp4eVK1dyxhln0N3dXZu7OO10lMvl2r1r0huZOdTbI0vQ7wMukNRLdejmImAA2AVcAdwCbAXuylqkza1YLDIwMMDXv/51vv/97/OWt7yldnn5rbfeysjISJsrtLxJh3FKpRKvvvoqQ0NDvP766xw7dozh4eHamDz4JmXtlmWM/gFJtwMPAhXgIapDMf8J3CLpb5NlNzSjUJvd0NAQPT09HDhwgH379vHwww/XelNHjx5tc3WWJ2lgj42NcfToUX75y18yODjI+Pg4o6OjlMtlyuXycePsDvn2ynTWTURsB7ZPWfwcsCnL77XGjI+P88orrwDw8ssv1w5w+eOyNVO6P42OjvLqq68yOjrKwYMHgepB1PTL+13n8JWxOTI5OcnQ0FDtxma28HXy3AJjY2O1oZr00yN4mKYTOehzyCGfH50cmFPPfbfOlekWCGZm1vkc9GZmOeegNzPLOQe9mVnOOejNzHLOQW9mlnMOejOznHPQm5nlnIPezCznHPRmZjnnoDczy7k5g17SjZIOSnqsblmfpHslPZN8X5ksl6SvSdoj6RFJ57eyeDMzm9uJ9Oi/DVwyZdnVwH0RsQG4L3kO1akENyRf2/Ck4GZmbTdn0EfET4DXpizeDOxMHu8ELq9b/p2oup/qtIKrm1Ws2WKUTt1n1qhGx+hPj4gDAMn305LlZwIv1q03mCx7A0nbJA1IGhgeHm6wDLP86+RbFdvC0OyDsdN1PabdSyNiR0RsjIiNvb29TS7DbOGp77m7F2/N1GjQv5IOySTfDybLB4Gz6tZbC7zUeHlmi4ND3lqp0aC/G9iaPN4K3FW3/OPJ2TcXAEfSIR4zm1n98Iyn4rNmm3MqQUk3A+8F+iUNUp0M/EvAbZKuBPYBH01Wvwe4DNgDDAOfaEHNZgtKV1fXrOEtCUmeAtJaZs6gj4iPzfDSRdOsG8BVWYsyy4s0xOGNB1Xrh2jcg7dW8uTgZi0023i7w93mi2+BYNYi9T15D8tYOznozcxyzkM3Zi3is2esU7hHb2aWc+7RmzXB1LNr3JO3TuKgN2sCB7t1Mge9WZM47K1TeYzezCznHPRmZjnnoDczyzkHvZlZzjnozcxybs6gl3SjpIOSHqtb9veSnpT0iKTvSVpR99o1kvZIekrSB1pVuJlZoxbb5C4n0qP/NnDJlGX3Ar8REW8HngauAZB0LrAFOC/5mX+VVGhatWZmdtLmDPqI+Anw2pRlP4yISvL0fqpTBgJsBm6JiHJEPE91ApJNTazXzCwz9+hP3h8DP0genwm8WPfaYLLsDSRtkzQgaWB4eLgJZZiZzSy9TUVX1+I7NJmpxZKuBSrATemiaVab9nLBiNgRERsjYmNvb2+WMszM5lR/D6LF1qNv+BYIkrYCHwQuil9d+z0InFW32lrgpcbLMzNrjvpwX2wTwTTUo5d0CfB54MMRUT/ucjewRVKPpPXABuCn2cs0M8sm7dFPTk4uuvsSzdmjl3Qz8F6gX9IgsJ3qWTY9wL3JX8n7I+JPIuJxSbcBv6A6pHNVREy0qngzM5vbnEEfER+bZvENs6z/ReCLWYoyM7PmWXyHn83MFhkHvZlZzjnozcxyzkFvZpZzDnozs5xz0JuZ5ZyD3sws5xz0ZmY556A3M8s5B72ZWc456M3Mcs5Bb2aWcw1NDl732mclhaT+5LkkfS2ZHPwRSee3omgzMztxjU4OjqSzgN8F9tUtvpTqPeg3ANuA67OXaGZmWTQ0OXjiq8DnOH6qwM3Ad6LqfmCFpNVNqdTMzBrS6AxTHwb2R8TDU1464cnBzcxsfpz0nLGSeoFrgfdP9/I0y6ads0vSNqrDOyxfvvxkyzAzsxPUSI/+HGA98LCkF6hOAP6gpDM4icnBI2JHRGyMiI29vb0NlGFmZifipIM+Ih6NiNMiYl1ErKMa7udHxMtUJwf/eHL2zQXAkYg40NySzczsZJzI6ZU3A/8LvFXSoKQrZ1n9HuA5YA/wTeCTTanSzMwa1ujk4PWvr6t7HMBV2csyM7Nm8ZWxZh1Cmu5cBrPsHPRmHaL6gdis+Rz0ZmY556A3M8s5B72ZWc456M3Mcs5Bb2aWcw56M7OcO+mbmrXS9u3b212C2bS8b9pC5h69mVnOqRMu0pB0CDgGvNruWlqgn3y2C9y2hSqvbctru2Dmtv1aRKya64c7IugBJA1ExMZ219FseW0XuG0LVV7bltd2Qfa2eejGzCznHPRmZjnXSUG/o90FtEhe2wVu20KV17bltV2QsW0dM0ZvZmat0Uk9ejMza4G2B72kSyQ9JWmPpKvbXU9Wkl6Q9Kik3ZIGkmV9ku6V9EzyfWW76zwRkm6UdFDSY3XLpm1LMk/w15Lt+Iik89tX+exmaNcXJO1PtttuSZfVvXZN0q6nJH2gPVWfGElnSdol6QlJj0v6dLI8D9ttprYt6G0naYmkn0p6OGnXdcny9ZIeSLbZrZJKyfKe5Pme5PV1c75JRLTtCygAzwJnAyXgYeDcdtbUhDa9APRPWfZ3wNXJ46uBL7e7zhNsy3uA84HH5moLcBnwA0DABcAD7a7/JNv1BeCz06x7brJf9gDrk/210O42zNK21cD5yeM3AU8nbcjDdpupbQt62yX/9kuTx0XggWRb3AZsSZZ/A/jT5PEngW8kj7cAt871Hu3u0W8C9kTEcxExBtwCbG5zTa2wGdiZPN4JXN7GWk5YRPwEeG3K4pnashn4TlTdD6yQtHp+Kj05M7RrJpuBWyKiHBHPU534flPLissoIg5ExIPJ46PAE8CZ5GO7zdS2mSyIbZf82w8lT4vJVwDvA25Plk/dZum2vB24SHPMQ9nuoD8TeLHu+SCzb7iFIIAfSvq5pG3JstMj4gBUd1bgtLZVl91MbcnDtvxUMnxxY93w2oJtV/KR/p1Ue4i52m5T2gYLfNtJKkjaDRwE7qX66eNwRFSSVeprr7Uref0I8ObZfn+7g366v0IL/TSgd0fE+cClwFWS3tPugubJQt+W1wPnAO8ADgD/mCxfkO2StBS4A/hMRLw+26rTLOvo9k3TtgW/7SJiIiLeAayl+qnjbdOtlnw/6Xa1O+gHgbPqnq8FXmpTLU0RES8l3w8C36O60V5JPw4n3w+2r8LMZmrLgt6WEfFK8p9tEvgmv/qIv+DaJalINQhviog7k8W52G7TtS1P2y4iDgM/pjpGv0JSeofh+tpr7UpeX84cQ5HtDvqfARuSo8slqgcW7m5zTQ2TdKqkN6WPgfcDj1Ft09Zkta3AXe2psClmasvdwMeTszguAI6kQwULwZRx6d+nut2g2q4tyZkO64ENwE/nu74TlYzV3gA8ERFfqXtpwW+3mdq20LedpFWSViSPTwEupnr8YRdwRbLa1G2WbssrgB9FcmR2Rh1wxPkyqkfPnwWubXc9GdtyNtWj/A8Dj6ftoTp+dh/wTPK9r921nmB7bqb6UXicai/iypnaQvXj5L8k2/FRYGO76z/Jdv17UvcjyX+k1XXrX5u06yng0nbXP0fbfofqx/hHgN3J12U52W4ztW1Bbzvg7cBDSf2PAX+TLD+b6h+mPcB3gZ5k+ZLk+Z7k9bPneg9fGWtmlnPtHroxM7MWc9CbmeWcg97MLOcc9GZmOeegNzPLOQe9mVnOOejNzHLOQW9mlnP/DwlogvOI0MlaAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object ID:  TXS 1455+253 TXS 1421+006\n",
      "GroundTruth:   FRII  FRII\n"
     ]
    }
   ],
   "source": [
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images2_tr))\n",
    "print('Object ID: ', ' '.join('%5s' % object_id_tr[j] for j in range(batch_size_train)))\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels_tr[j]] for j in range(batch_size_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a neural network that takes greyscale images as input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 34 * 34, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # conv1 output width: input_width - (kernel_size - 1) => 150 - (5-1) = 146\n",
    "        # pool 1 output width: int(input_width/2) => 73\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        # conv2 output width: input_width - (kernel_size - 1) => 73 - (5-1) = 69\n",
    "        # pool 2 output width: int(input_width/2) => 34\n",
    "        x = self.pool(F.relu(self.conv2(x)))  \n",
    "        x = x.view(-1, 16 * 34 * 34)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 6, 146, 146]             156\n",
      "         MaxPool2d-2            [-1, 6, 73, 73]               0\n",
      "            Conv2d-3           [-1, 16, 69, 69]           2,416\n",
      "         MaxPool2d-4           [-1, 16, 34, 34]               0\n",
      "            Linear-5                  [-1, 120]       2,219,640\n",
      "            Linear-6                   [-1, 84]          10,164\n",
      "            Linear-7                   [-1, 10]             850\n",
      "================================================================\n",
      "Total params: 2,233,226\n",
      "Trainable params: 2,233,226\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.09\n",
      "Forward/backward pass size (MB): 1.94\n",
      "Params size (MB): 8.52\n",
      "Estimated Total Size (MB): 10.55\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "summary(net,(1,150,150))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use Classification Cross-Entropy loss and Adagrad with momentum for optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adagrad(net.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run 10 epochs of training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    50] loss: 0.964\n",
      "[1,   100] loss: 0.697\n",
      "[1,   150] loss: 0.710\n",
      "[1,   200] loss: 0.687\n",
      "[2,    50] loss: 0.681\n",
      "[2,   100] loss: 0.612\n",
      "[2,   150] loss: 0.651\n",
      "[2,   200] loss: 0.568\n",
      "[3,    50] loss: 0.577\n",
      "[3,   100] loss: 0.586\n",
      "[3,   150] loss: 0.538\n",
      "[3,   200] loss: 0.574\n",
      "[4,    50] loss: 0.547\n",
      "[4,   100] loss: 0.514\n",
      "[4,   150] loss: 0.514\n",
      "[4,   200] loss: 0.548\n",
      "[5,    50] loss: 0.428\n",
      "[5,   100] loss: 0.533\n",
      "[5,   150] loss: 0.473\n",
      "[5,   200] loss: 0.568\n",
      "[6,    50] loss: 0.522\n",
      "[6,   100] loss: 0.518\n",
      "[6,   150] loss: 0.514\n",
      "[6,   200] loss: 0.392\n",
      "[7,    50] loss: 0.439\n",
      "[7,   100] loss: 0.430\n",
      "[7,   150] loss: 0.491\n",
      "[7,   200] loss: 0.440\n",
      "[8,    50] loss: 0.412\n",
      "[8,   100] loss: 0.461\n",
      "[8,   150] loss: 0.494\n",
      "[8,   200] loss: 0.322\n",
      "[9,    50] loss: 0.405\n",
      "[9,   100] loss: 0.497\n",
      "[9,   150] loss: 0.400\n",
      "[9,   200] loss: 0.434\n",
      "[10,    50] loss: 0.383\n",
      "[10,   100] loss: 0.421\n",
      "[10,   150] loss: 0.346\n",
      "[10,   200] loss: 0.385\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "nepoch = 10  # number of epochs\n",
    "print_num = 50\n",
    "for epoch in range(nepoch):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        \n",
    "        images1,images2,object_id,labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(images2) # train with FIRST images\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % print_num == (print_num-1):    # print every 50 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / print_num))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll try out a couple of test samples just for visual kicks. First load them up and take a look at the true labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(testloader)\n",
    "images1_te,images2_te,object_id_te,labels_te = dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object ID:  TXS 1529+110 TXS 1459+133\n",
      "GroundTruth:   FRII  FRII\n"
     ]
    }
   ],
   "source": [
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images2_te))\n",
    "print('Object ID: ', ' '.join('%5s' % object_id_te[j] for j in range(batch_size_test)))\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels_te[j]] for j in range(batch_size_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then see what the network predicts that they are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = net(images2_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:   FRII   FRI\n"
     ]
    }
   ],
   "source": [
    "_, predicted = torch.max(outputs, 1)\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]] for j in range(batch_size_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now calculate the overall accuracy of the network on **all** the test images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 198 test images: 84 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images1,images2,object_id,labels = data\n",
    "        outputs = net(images2)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 198 test images: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a imbalanced dataset, so let's take a look at the accuracy for individual classes (class recall):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_correct = list(0. for i in range(2))\n",
    "class_total = list(0. for i in range(2))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images1,images2,object_id,labels = data\n",
    "        outputs = net(images2)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(batch_size_test):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class recall of   FRI : 82 %\n",
      "Class recall of  FRII : 82 %\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(classes)):\n",
    "    print('Class recall of %5s : %2d %%' % (classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
